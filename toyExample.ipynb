{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-01 18:36:10,417 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2018-12-01 18:36:12,117 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir /user/jupyter\n",
    "!hdfs dfs -put data/* /user/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import pyspark as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 2.7.15\n",
      "PySpark Version: 2.4.0\n",
      "java version \"1.8.0_131\"\n",
      "Java(TM) SE Runtime Environment (build 1.8.0_131-b11)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)\n",
      "Scala code runner version 2.11.12 -- Copyright 2002-2017, LAMP/EPFL\n"
     ]
    }
   ],
   "source": [
    "print('Python Version: '+platform.python_version())\n",
    "print('PySpark Version: '+ps.__version__)\n",
    "!java -version\n",
    "!scala -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkContext = ps.SparkContext(master='spark://ryans-macbook:7077')\n",
    "spark = ps.sql.SparkSession(sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'hdfs://ryans-macbook:9000/user/jupyter/%s'\n",
    "train_file_name = 'toyTrain.csv'\n",
    "train_path = root % train_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(train_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+--------+\n",
      "| Id|   one|   two| three|Response|\n",
      "+---+------+------+------+--------+\n",
      "|  0|-0.179| 0.003| 0.022|       1|\n",
      "|  1|-0.161| 0.173|  null|       1|\n",
      "|  2|  null|-0.258|  0.03|       0|\n",
      "|  3|  null|  null|  0.07|       0|\n",
      "|  4|  null| 0.075|  null|       1|\n",
      "|  5| 0.168|  null|  null|       1|\n",
      "|  6|  null|  null| 0.045|       1|\n",
      "|  7|-0.249| 0.023|-0.021|       1|\n",
      "|  8|-0.007|-0.036|  null|       0|\n",
      "|  9|  null| -0.01|  0.07|       0|\n",
      "| 10| 0.312|  null|  null|       0|\n",
      "| 11| 0.275|-0.036|  0.07|       0|\n",
      "| 12| 0.056|  0.03|  null|       1|\n",
      "| 13|  null|  null| 0.116|       0|\n",
      "| 14|  null|  null|-0.339|       0|\n",
      "| 15| 0.031|  null|  null|       1|\n",
      "| 16| 0.031| 0.023|  0.33|       0|\n",
      "| 17|-0.013| 0.075|  null|       0|\n",
      "+---+------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define a function to aggregate the columns of the DataFrame:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log1p\n",
    "def rowaggs(x):\n",
    "    r = filter(None, x[1:-1])\n",
    "    avg = 0\n",
    "    if len(r) != 0:\n",
    "        avg = sum(r)/len(r)\n",
    "    return len(r), avg, avg**2, log1p(avg), x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cntX', 'avgX', 'avg2X', '1plogavgX', df.columns[-1]]\n",
    "df = df.rdd.map(rowaggs).toDF(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+--------+\n",
      "|cntX|                avgX|               avg2X|           1plogavgX|Response|\n",
      "+----+--------------------+--------------------+--------------------+--------+\n",
      "|   3|-0.05133333333333...|0.002635111111111111|-0.05269778900044...|       1|\n",
      "|   2|0.005999999999999...| 3.59999999999999E-5|0.005982071677547456|       1|\n",
      "|   2|              -0.114|            0.012996|-0.12103832837705611|       0|\n",
      "|   1|                0.07|0.004900000000000001| 0.06765864847381481|       0|\n",
      "|   1|               0.075|            0.005625|  0.0723206615796261|       1|\n",
      "|   1|               0.168|0.028224000000000003| 0.15529288440603534|       1|\n",
      "|   1|               0.045|            0.002025| 0.04401688541677432|       1|\n",
      "|   3|-0.08233333333333333|0.006778777777777777|-0.08592106250763942|       1|\n",
      "|   2|             -0.0215|4.622499999999999...|-0.02173449214600613|       0|\n",
      "|   2|0.030000000000000002|9.000000000000002E-4|0.029558802241544405|       0|\n",
      "|   1|               0.312|            0.097344|  0.2715526905218973|       0|\n",
      "|   3| 0.10300000000000002|0.010609000000000004| 0.09803374027136544|       0|\n",
      "|   2|               0.043|0.001848999999999...| 0.04210117601863539|       1|\n",
      "|   1|               0.116|0.013456000000000001| 0.10975086395911919|       0|\n",
      "|   1|              -0.339| 0.11492100000000001| -0.4140014391304508|       0|\n",
      "|   1|               0.031|9.609999999999999E-4|0.030529205034822874|       1|\n",
      "|   3|               0.128|            0.016384| 0.12044615307586715|       0|\n",
      "|   2|               0.031|9.609999999999999E-4|0.030529205034822874|       0|\n",
      "+----+--------------------+--------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define function to label outliers.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "def nameOuts(col_name, iqrx):\n",
    "    quants = df.approxQuantile([col_name],[.25,.75],0)\n",
    "    q1, q3 = quants[0][0], quants[0][1]\n",
    "    iqr = q3 - q1\n",
    "    lb = q1 - iqrx * iqr\n",
    "    ub = q3 + iqrx * iqr\n",
    "    return when((df[col_name]<lb) | (df[col_name]>ub),1).otherwise(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in df.columns[1:-1]:\n",
    "    df = df.withColumn('%s_O' % col_name, nameOuts(col_name, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+--------+------+-------+-----------+\n",
      "|cntX|                avgX|               avg2X|           1plogavgX|Response|avgX_O|avg2X_O|1plogavgX_O|\n",
      "+----+--------------------+--------------------+--------------------+--------+------+-------+-----------+\n",
      "|   3|-0.05133333333333...|0.002635111111111111|-0.05269778900044...|       1|     0|      0|          0|\n",
      "|   2|0.005999999999999...| 3.59999999999999E-5|0.005982071677547456|       1|     0|      0|          0|\n",
      "|   2|              -0.114|            0.012996|-0.12103832837705611|       0|     0|      0|          0|\n",
      "|   1|                0.07|0.004900000000000001| 0.06765864847381481|       0|     0|      0|          0|\n",
      "|   1|               0.075|            0.005625|  0.0723206615796261|       1|     0|      0|          0|\n",
      "|   1|               0.168|0.028224000000000003| 0.15529288440603534|       1|     0|      0|          0|\n",
      "|   1|               0.045|            0.002025| 0.04401688541677432|       1|     0|      0|          0|\n",
      "|   3|-0.08233333333333333|0.006778777777777777|-0.08592106250763942|       1|     0|      0|          0|\n",
      "|   2|             -0.0215|4.622499999999999...|-0.02173449214600613|       0|     0|      0|          0|\n",
      "|   2|0.030000000000000002|9.000000000000002E-4|0.029558802241544405|       0|     0|      0|          0|\n",
      "|   1|               0.312|            0.097344|  0.2715526905218973|       0|     1|      1|          0|\n",
      "|   3| 0.10300000000000002|0.010609000000000004| 0.09803374027136544|       0|     0|      0|          0|\n",
      "|   2|               0.043|0.001848999999999...| 0.04210117601863539|       1|     0|      0|          0|\n",
      "|   1|               0.116|0.013456000000000001| 0.10975086395911919|       0|     0|      0|          0|\n",
      "|   1|              -0.339| 0.11492100000000001| -0.4140014391304508|       0|     1|      1|          1|\n",
      "|   1|               0.031|9.609999999999999E-4|0.030529205034822874|       1|     0|      0|          0|\n",
      "|   3|               0.128|            0.016384| 0.12044615307586715|       0|     0|      0|          0|\n",
      "|   2|               0.031|9.609999999999999E-4|0.030529205034822874|       0|     0|      0|          0|\n",
      "+----+--------------------+--------------------+--------------------+--------+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.insert(4, 'O')\n",
    "df = df.rdd.map(lambda x:(x[0],x[1],x[2],x[3],sum(x[5:]),x[4])).toDF(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+---+--------+\n",
      "|cntX|                avgX|               avg2X|           1plogavgX|  O|Response|\n",
      "+----+--------------------+--------------------+--------------------+---+--------+\n",
      "|   3|-0.05133333333333...|0.002635111111111111|-0.05269778900044...|  0|       1|\n",
      "|   2|0.005999999999999...| 3.59999999999999E-5|0.005982071677547456|  0|       1|\n",
      "|   2|              -0.114|            0.012996|-0.12103832837705611|  0|       0|\n",
      "|   1|                0.07|0.004900000000000001| 0.06765864847381481|  0|       0|\n",
      "|   1|               0.075|            0.005625|  0.0723206615796261|  0|       1|\n",
      "|   1|               0.168|0.028224000000000003| 0.15529288440603534|  0|       1|\n",
      "|   1|               0.045|            0.002025| 0.04401688541677432|  0|       1|\n",
      "|   3|-0.08233333333333333|0.006778777777777777|-0.08592106250763942|  0|       1|\n",
      "|   2|             -0.0215|4.622499999999999...|-0.02173449214600613|  0|       0|\n",
      "|   2|0.030000000000000002|9.000000000000002E-4|0.029558802241544405|  0|       0|\n",
      "|   1|               0.312|            0.097344|  0.2715526905218973|  2|       0|\n",
      "|   3| 0.10300000000000002|0.010609000000000004| 0.09803374027136544|  0|       0|\n",
      "|   2|               0.043|0.001848999999999...| 0.04210117601863539|  0|       1|\n",
      "|   1|               0.116|0.013456000000000001| 0.10975086395911919|  0|       0|\n",
      "|   1|              -0.339| 0.11492100000000001| -0.4140014391304508|  3|       0|\n",
      "|   1|               0.031|9.609999999999999E-4|0.030529205034822874|  0|       1|\n",
      "|   3|               0.128|            0.016384| 0.12044615307586715|  0|       0|\n",
      "|   2|               0.031|9.609999999999999E-4|0.030529205034822874|  0|       0|\n",
      "+----+--------------------+--------------------+--------------------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Put munged data into hdfs:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dt = datetime.now().time()\n",
    "munged_file_name = str(dt).replace(':', '_') + '_' + train_file_name\n",
    "munged_path = root % munged_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(munged_path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create vectors for Machine Learning:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = cols[:-1]\n",
    "assembler = VectorAssembler(inputCols=numericCols,\\\n",
    "                            outputCol='features',\\\n",
    "                            handleInvalid='keep')\n",
    "\n",
    "stages = [assembler]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "cols = ['features', 'Response']\n",
    "df = pipelineModel.transform(df).select(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Response|\n",
      "+--------------------+--------+\n",
      "|[3.0,-0.051333333...|       1|\n",
      "|[2.0,0.0059999999...|       1|\n",
      "|[2.0,-0.114,0.012...|       0|\n",
      "|[1.0,0.07,0.00490...|       0|\n",
      "|[1.0,0.075,0.0056...|       1|\n",
      "|[1.0,0.168,0.0282...|       1|\n",
      "|[1.0,0.045,0.0020...|       1|\n",
      "|[3.0,-0.082333333...|       1|\n",
      "|[2.0,-0.0215,4.62...|       0|\n",
      "|[2.0,0.0300000000...|       0|\n",
      "|[1.0,0.312,0.0973...|       0|\n",
      "|[3.0,0.1030000000...|       0|\n",
      "|[2.0,0.043,0.0018...|       1|\n",
      "|[1.0,0.116,0.0134...|       0|\n",
      "|[1.0,-0.339,0.114...|       0|\n",
      "|[1.0,0.031,9.6099...|       1|\n",
      "|[3.0,0.128,0.0163...|       0|\n",
      "|[2.0,0.031,9.6099...|       0|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Response: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split off training data and fit LogisticRegression:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "X_train, X_test = df.randomSplit([.8, .2], 42)\n",
    "lr = LogisticRegression(featuresCol='features',\\\n",
    "                        labelCol='Response',\\\n",
    "                        maxIter=2,\\\n",
    "                        regParam=.3,\\\n",
    "                        elasticNetParam=.8)\n",
    "\n",
    "lrModel = lr.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cross validate model performance:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model got a areaUnderROC of 0.5\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "bce = BinaryClassificationEvaluator(labelCol='Response')\n",
    "train_preds = lrModel.transform(X_test)\n",
    "score = bce.evaluate(train_preds)\n",
    "print('The Model got a %s of %s' % (bce.getMetricName(), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().time()\n",
    "date_name = str(dt).replace(':', '_')\n",
    "mod_path = 'models/%s_LR' % date_name\n",
    "lrModel.save(mod_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now use this model to make predictions on the test data.__\n",
    "\n",
    "__Test data has slight difference in munge due to missing label.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name = 'toyTest.csv'\n",
    "test_path = root % test_file_name\n",
    "df = spark.read.csv(test_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n",
      "| Id|   one|   two| three|\n",
      "+---+------+------+------+\n",
      "|  0|-0.179| 0.003| 0.022|\n",
      "|  1|-0.161| 0.173|  null|\n",
      "|  2|  null|-0.258|  0.03|\n",
      "|  3|  null|  null|  0.07|\n",
      "|  4|  null| 0.075|  null|\n",
      "|  5| 0.168|  null|  null|\n",
      "|  6|  null|  null| 0.045|\n",
      "|  7|-0.249| 0.023|-0.021|\n",
      "|  8|-0.007|-0.036|  null|\n",
      "|  9|  null| -0.01|  0.07|\n",
      "| 10| 0.312|  null|  null|\n",
      "| 11| 0.275|-0.036|  0.07|\n",
      "| 12| 0.056|  0.03|  null|\n",
      "| 13|  null|  null| 0.116|\n",
      "| 14|  null|  null|-0.339|\n",
      "| 15| 0.031|  null|  null|\n",
      "| 16| 0.031| 0.023|  0.33|\n",
      "| 17|-0.013| 0.075|  null|\n",
      "+---+------+------+------+\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- one: double (nullable = true)\n",
      " |-- two: double (nullable = true)\n",
      " |-- three: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(), df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowaggsNoLabel(x):\n",
    "    r = filter(None, x[1:])\n",
    "    avrg = 0\n",
    "    if len(r) != 0:\n",
    "        avrg = sum(r)/len(r)\n",
    "    return x[0], len(r), avrg, avrg**2, log1p(avrg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [df.columns[0], 'cntX', 'avgX', 'avg2X', '1plogavgX']\n",
    "df = df.rdd.map(rowaggsNoLabel).toDF(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------------------+--------------------+--------------------+\n",
      "| Id|cntX|                avgX|               avg2X|           1plogavgX|\n",
      "+---+----+--------------------+--------------------+--------------------+\n",
      "|  0|   3|-0.05133333333333...|0.002635111111111111|-0.05269778900044...|\n",
      "|  1|   2|0.005999999999999...| 3.59999999999999E-5|0.005982071677547456|\n",
      "|  2|   2|              -0.114|            0.012996|-0.12103832837705611|\n",
      "|  3|   1|                0.07|0.004900000000000001| 0.06765864847381481|\n",
      "|  4|   1|               0.075|            0.005625|  0.0723206615796261|\n",
      "|  5|   1|               0.168|0.028224000000000003| 0.15529288440603534|\n",
      "|  6|   1|               0.045|            0.002025| 0.04401688541677432|\n",
      "|  7|   3|-0.08233333333333333|0.006778777777777777|-0.08592106250763942|\n",
      "|  8|   2|             -0.0215|4.622499999999999...|-0.02173449214600613|\n",
      "|  9|   2|0.030000000000000002|9.000000000000002E-4|0.029558802241544405|\n",
      "| 10|   1|               0.312|            0.097344|  0.2715526905218973|\n",
      "| 11|   3| 0.10300000000000002|0.010609000000000004| 0.09803374027136544|\n",
      "| 12|   2|               0.043|0.001848999999999...| 0.04210117601863539|\n",
      "| 13|   1|               0.116|0.013456000000000001| 0.10975086395911919|\n",
      "| 14|   1|              -0.339| 0.11492100000000001| -0.4140014391304508|\n",
      "| 15|   1|               0.031|9.609999999999999E-4|0.030529205034822874|\n",
      "| 16|   3|               0.128|            0.016384| 0.12044615307586715|\n",
      "| 17|   2|               0.031|9.609999999999999E-4|0.030529205034822874|\n",
      "+---+----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in df.columns[2:]:\n",
    "    df = df.withColumn('%s_O' % col_name, nameOuts(col_name, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------------------+--------------------+--------------------+------+-------+-----------+\n",
      "| Id|cntX|                avgX|               avg2X|           1plogavgX|avgX_O|avg2X_O|1plogavgX_O|\n",
      "+---+----+--------------------+--------------------+--------------------+------+-------+-----------+\n",
      "|  0|   3|-0.05133333333333...|0.002635111111111111|-0.05269778900044...|     0|      0|          0|\n",
      "|  1|   2|0.005999999999999...| 3.59999999999999E-5|0.005982071677547456|     0|      0|          0|\n",
      "|  2|   2|              -0.114|            0.012996|-0.12103832837705611|     0|      0|          0|\n",
      "|  3|   1|                0.07|0.004900000000000001| 0.06765864847381481|     0|      0|          0|\n",
      "|  4|   1|               0.075|            0.005625|  0.0723206615796261|     0|      0|          0|\n",
      "|  5|   1|               0.168|0.028224000000000003| 0.15529288440603534|     0|      0|          0|\n",
      "|  6|   1|               0.045|            0.002025| 0.04401688541677432|     0|      0|          0|\n",
      "|  7|   3|-0.08233333333333333|0.006778777777777777|-0.08592106250763942|     0|      0|          0|\n",
      "|  8|   2|             -0.0215|4.622499999999999...|-0.02173449214600613|     0|      0|          0|\n",
      "|  9|   2|0.030000000000000002|9.000000000000002E-4|0.029558802241544405|     0|      0|          0|\n",
      "| 10|   1|               0.312|            0.097344|  0.2715526905218973|     1|      1|          0|\n",
      "| 11|   3| 0.10300000000000002|0.010609000000000004| 0.09803374027136544|     0|      0|          0|\n",
      "| 12|   2|               0.043|0.001848999999999...| 0.04210117601863539|     0|      0|          0|\n",
      "| 13|   1|               0.116|0.013456000000000001| 0.10975086395911919|     0|      0|          0|\n",
      "| 14|   1|              -0.339| 0.11492100000000001| -0.4140014391304508|     1|      1|          1|\n",
      "| 15|   1|               0.031|9.609999999999999E-4|0.030529205034822874|     0|      0|          0|\n",
      "| 16|   3|               0.128|            0.016384| 0.12044615307586715|     0|      0|          0|\n",
      "| 17|   2|               0.031|9.609999999999999E-4|0.030529205034822874|     0|      0|          0|\n",
      "+---+----+--------------------+--------------------+--------------------+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------------------+--------------------+--------------------+---+\n",
      "| Id|cntX|                avgX|               avg2X|           1plogavgX|  O|\n",
      "+---+----+--------------------+--------------------+--------------------+---+\n",
      "|  0|   3|-0.05133333333333...|0.002635111111111111|-0.05269778900044...|  0|\n",
      "|  1|   2|0.005999999999999...| 3.59999999999999E-5|0.005982071677547456|  0|\n",
      "|  2|   2|              -0.114|            0.012996|-0.12103832837705611|  0|\n",
      "|  3|   1|                0.07|0.004900000000000001| 0.06765864847381481|  0|\n",
      "|  4|   1|               0.075|            0.005625|  0.0723206615796261|  0|\n",
      "|  5|   1|               0.168|0.028224000000000003| 0.15529288440603534|  0|\n",
      "|  6|   1|               0.045|            0.002025| 0.04401688541677432|  0|\n",
      "|  7|   3|-0.08233333333333333|0.006778777777777777|-0.08592106250763942|  0|\n",
      "|  8|   2|             -0.0215|4.622499999999999...|-0.02173449214600613|  0|\n",
      "|  9|   2|0.030000000000000002|9.000000000000002E-4|0.029558802241544405|  0|\n",
      "| 10|   1|               0.312|            0.097344|  0.2715526905218973|  2|\n",
      "| 11|   3| 0.10300000000000002|0.010609000000000004| 0.09803374027136544|  0|\n",
      "| 12|   2|               0.043|0.001848999999999...| 0.04210117601863539|  0|\n",
      "| 13|   1|               0.116|0.013456000000000001| 0.10975086395911919|  0|\n",
      "| 14|   1|              -0.339| 0.11492100000000001| -0.4140014391304508|  3|\n",
      "| 15|   1|               0.031|9.609999999999999E-4|0.030529205034822874|  0|\n",
      "| 16|   3|               0.128|            0.016384| 0.12044615307586715|  0|\n",
      "| 17|   2|               0.031|9.609999999999999E-4|0.030529205034822874|  0|\n",
      "+---+----+--------------------+--------------------+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols.append('O')\n",
    "df = df.rdd.map(lambda x:(x[0],x[1],x[2],x[3],x[4],sum(x[5:]))).toDF(cols)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__After munge, vectorize for Model:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = cols[1:]\n",
    "assembler = VectorAssembler(inputCols=numericCols,\\\n",
    "                            outputCol='features',\\\n",
    "                            handleInvalid='keep')\n",
    "\n",
    "pipelineModel = pipeline.fit(df)\n",
    "cols = ['Id', 'features']\n",
    "df = pipelineModel.transform(df).select(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| Id|            features|\n",
      "+---+--------------------+\n",
      "|  0|[3.0,-0.051333333...|\n",
      "|  1|[2.0,0.0059999999...|\n",
      "|  2|[2.0,-0.114,0.012...|\n",
      "|  3|[1.0,0.07,0.00490...|\n",
      "|  4|[1.0,0.075,0.0056...|\n",
      "|  5|[1.0,0.168,0.0282...|\n",
      "|  6|[1.0,0.045,0.0020...|\n",
      "|  7|[3.0,-0.082333333...|\n",
      "|  8|[2.0,-0.0215,4.62...|\n",
      "|  9|[2.0,0.0300000000...|\n",
      "| 10|[1.0,0.312,0.0973...|\n",
      "| 11|[3.0,0.1030000000...|\n",
      "| 12|[2.0,0.043,0.0018...|\n",
      "| 13|[1.0,0.116,0.0134...|\n",
      "| 14|[1.0,-0.339,0.114...|\n",
      "| 15|[1.0,0.031,9.6099...|\n",
      "| 16|[3.0,0.128,0.0163...|\n",
      "| 17|[2.0,0.031,9.6099...|\n",
      "+---+--------------------+\n",
      "\n",
      "root\n",
      " |-- Id: long (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(), df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Use model to make predictions, then put in hdfs (loading persisted model just to show how):__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "lrModel2 = LogisticRegressionModel.load(mod_path)\n",
    "preds = lrModel2.transform(df).selectExpr('Id', 'CAST(prediction as INT) as Response')\n",
    "dt = datetime.now().time()\n",
    "date_name = str(dt).replace(':', '_')\n",
    "preds.write.csv('%s' % root % date_name + '_PREDS.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-01 18:39:01,561 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 4 items\n",
      "drwxr-xr-x   - ryanbusby supergroup          0 2018-12-01 18:37 /user/jupyter/18_37_42.266082_toyTrain.csv\n",
      "drwxr-xr-x   - ryanbusby supergroup          0 2018-12-01 18:38 /user/jupyter/18_38_58.325233_PREDS.csv\n",
      "-rw-r--r--   1 ryanbusby supergroup        296 2018-12-01 18:36 /user/jupyter/toyTest.csv\n",
      "-rw-r--r--   1 ryanbusby supergroup        341 2018-12-01 18:36 /user/jupyter/toyTrain.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
